{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094566d5-8c22-42d5-9006-afb1b4cdf08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "dpi_default = mpl.rcParams['figure.dpi']\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "def json_read(filename):\n",
    "        if (os.path.isfile(filename)):\n",
    "            with open(filename) as data_file:\n",
    "                data = json.load(data_file)\n",
    "            isfile=True;\n",
    "        else:\n",
    "            data={}\n",
    "            isfile=False;\n",
    "        return data, isfile     \n",
    "\n",
    "\n",
    "#db = '/disk/collab_BM_org/Tracer/data/tracer/'\n",
    "PATH_TO_BMCR_data = '...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8503cfbf-76f2-4700-9564-ff4b93bb7ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee702a-974f-41dc-adc6-36a8986c6a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = PATH_TO_BMCR_data+\"/BMCR_img_data/\"\n",
    "\n",
    "mids = [t.split(\"/\")[-1] for t in glob.glob(all_data+\"*R0*\") if os.path.isfile(t+\"/meta/validation_landmarks_ANTs.json\")]\n",
    "print(mids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bb3e6e-59b7-437d-8bc1-2d68a2de19f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27026a45-3271-4635-aba4-03dda4a9bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "experts = [\"ANTs\",\"A\",\"H\",\"N\"]\n",
    "datases = {}\n",
    "\n",
    "for ex in experts:\n",
    "    datases[ex] = {}\n",
    "    #datases[ex][\"l\n",
    "    table = None\n",
    "    valid = None\n",
    "    for m in mids:\n",
    "        #f = db + m + \"/annotations/landmarks_\"+ex+\".ano.json\"\n",
    "        f = all_data + m + \"/meta/validation_landmarks_\"+ex+\".json\"\n",
    "        lm, success = json_read(f)\n",
    "        assert(success)\n",
    "        lm_pts = np.array([pt[\"coords\"] for pt in lm[\"annotations\"][0][\"points\"]])[:,:3]\n",
    "        lm_valid = np.array([pt[\"size\"] for pt in lm[\"annotations\"][0][\"points\"]])[:,None]\n",
    "        \n",
    "        table = lm_pts[...,None] if table is None else np.concatenate((table,lm_pts[...,None]),axis=2)\n",
    "        \n",
    "        valid = lm_valid[...,None] if valid is None else np.concatenate((valid,lm_valid[...,None]),axis=2)\n",
    "        assert(success)\n",
    "    datases[ex][\"lm\"] = table[:20,:,:]\n",
    "    datases[ex][\"valid\"] = valid[:20,:,:]\n",
    "    \n",
    "    if ex == \"ANTs\":\n",
    "        lm_names = [pt[\"name\"].replace(\"</span>&nbsp;\",\" \").replace('<span style=\"float: none;\">',\"\").replace(\"Sup\",\"sup\") for pt in lm[\"annotations\"][0][\"points\"]]\n",
    "        lm_names = [pt.replace(\"midline1\",\"midline\") for pt in lm_names]\n",
    "        lm_names = lm_names[:20]\n",
    "lm_names        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a66eb-ed56-4242-b4b0-4a82022dfea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ex in experts:\n",
    "    print(ex)\n",
    "    valid = np.min(datases[ex][\"valid\"],axis=(1,2))\n",
    "    print(valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e746142-0ef7-4bbf-a92f-7fb177130728",
   "metadata": {},
   "outputs": [],
   "source": [
    "init = True\n",
    "x_labels = []\n",
    "y_labels = []\n",
    "\n",
    "num_labels = 0\n",
    "\n",
    "comb_legend = []\n",
    "\n",
    "\n",
    "single_lm = [a for a,b in zip(range(len(lm_names)),lm_names) if not (\"right\" in b or \"left\" in b)]\n",
    "left_lm = [a for a,b in zip(range(len(lm_names)),lm_names) if \"left\" in b]\n",
    "right_lm = [a for a,b in zip(range(len(lm_names)),lm_names) if \"right\" in b]\n",
    "\n",
    "lm_names_merged_lr = [lm_names[l] for l in single_lm] + [lm_names[l].replace(\" left\",\"\") for l in left_lm]\n",
    "\n",
    "all_dists = {}\n",
    "all_dists_padded = {}\n",
    "\n",
    "for ex1_ in range(len(experts)):\n",
    "    ex1 = experts[ex1_]\n",
    "    init2 = True\n",
    "    for ex2_ in range(ex1_+1,len(experts)):\n",
    "        ex2 = experts[ex2_]\n",
    "        \n",
    "        x_labels += [ex1 +\" vs \"+ ex2]\n",
    "        comb_legend += [ex1 +\" vs \"+ ex2]\n",
    "        \n",
    "        D_ = datases[ex1][\"lm\"]-datases[ex2][\"lm\"]\n",
    "        Ds = np.concatenate((D_[single_lm,:,:],D_[single_lm,:,:]),axis=2)\n",
    "        \n",
    "        #non symmetric landmarks only appear once. Ds is for the mean, but we use this one to count absolute values\n",
    "        Ds_masked = np.concatenate((D_[single_lm,:,:],np.zeros(D_[single_lm,:,:].shape)),axis=2)\n",
    "        Dlr = np.concatenate((D_[left_lm,:,:],D_[right_lm,:,:]),axis=2)\n",
    "        \n",
    "        D = np.concatenate((Ds,Dlr),axis=0)\n",
    "        D_masked = np.concatenate((Ds_masked,Dlr),axis=0)\n",
    "        \n",
    "        \n",
    "        M = np.sqrt(np.sum(D**2,axis=1))\n",
    "        M_masked = np.sqrt(np.sum(D_masked**2,axis=1))\n",
    "        \n",
    "        all_dists_padded[ex1 +\" vs \"+ ex2] = M\n",
    "        all_dists[ex1 +\" vs \"+ ex2] = M_masked\n",
    "        \n",
    "        M_mean = M.mean(axis=1)\n",
    "        M_std = M.std(axis=1)\n",
    "\n",
    "        M_mean_mat = M_mean[:,None] if init else np.concatenate((M_mean_mat,M_mean[:,None]),axis=1)\n",
    "        M_std_mat = M_std[:,None] if init else np.concatenate((M_std_mat,M_std[:,None]),axis=1)\n",
    "        init = False\n",
    "\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "fig, ax = plt.subplots()\n",
    "plt.imshow(M_mean_mat,cmap=\"gray\")\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "ax.set_xticks(np.arange(len(x_labels)))\n",
    "ax.set_xticklabels(x_labels, rotation=90)\n",
    "\n",
    "ax.set_yticks(np.arange(len(lm_names_merged_lr)))\n",
    "ax.set_yticklabels(lm_names_merged_lr, rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('BMCR_Figures/Fig18/landmarks_matrix.pdf',bbox_inches='tight',  pad_inches = 0.1)\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b53f2b-85b4-401f-8943-2dcad1b7d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(all_dists.keys())\n",
    "\n",
    "init = True\n",
    "for a in range(3):\n",
    "    print(\"best ANTS candidate \",keys[a])\n",
    "    if init:\n",
    "        init=False\n",
    "        ants = all_dists_padded[keys[a]][...,None]\n",
    "        human = all_dists_padded[keys[a+3]][...,None]\n",
    "    else:\n",
    "        ants = np.concatenate((ants,all_dists_padded[keys[a]][...,None]),axis=2)\n",
    "        human = np.concatenate((human,all_dists_padded[keys[a+3]][...,None]),axis=2)\n",
    "ants = np.sort(ants,axis=2)[:,:,1]\n",
    "human = np.sort(human,axis=2)[:,:,1]     \n",
    "\n",
    "ants_and_human = np.concatenate((ants[...,None],human[...,None]),axis=2)\n",
    "M_mean = ants_and_human.mean(axis=1)\n",
    "M_std = ants_and_human.std(axis=1)\n",
    "\n",
    "\n",
    "M_mean_flattened = M_mean.reshape([-1])\n",
    "M_std_flattened = M_std.reshape([-1])\n",
    "flattened_indx = np.zeros(M_mean.shape)\n",
    "flattened_indx[:] = np.arange(2)[None,:]\n",
    "flattened_indx = flattened_indx.reshape([-1])\n",
    "\n",
    "flattened_lindx = np.zeros(M_mean.shape)\n",
    "flattened_lindx[:] = np.arange(M_mean.shape[0])[:,None]\n",
    "flattened_lindx = flattened_lindx.reshape([-1])\n",
    "\n",
    "sindx =  np.argsort(M_mean_flattened)\n",
    "comb = np.unique(flattened_indx)\n",
    "\n",
    "M_m_sort = M_mean_flattened[sindx]\n",
    "M_s_sort = M_std_flattened[sindx]\n",
    "M_i_sort = flattened_indx[sindx]\n",
    "M_l_sort = flattened_lindx[sindx]\n",
    "\n",
    "if True:\n",
    "    x_pos = np.arange(flattened_indx.shape[0])\n",
    "    fig, ax = plt.subplots()\n",
    "    L = []\n",
    "\n",
    "    for a in range(2):\n",
    "        x_pos_ = x_pos[M_i_sort == a]\n",
    "        y = M_m_sort[M_i_sort == a]\n",
    "        ye = M_s_sort[M_i_sort == a]\n",
    "\n",
    "        gray = (a % 3 ) / 3\n",
    "        if a %2 == 0:\n",
    "            ax.bar(x_pos_, y, yerr=ye,  align='center', alpha=0.5, ecolor='red', capsize=10, error_kw=dict(lw=0.8, capsize=1, capthick=0.8,lolims=True),color=(1,gray,gray,1))\n",
    "        else:\n",
    "            ax.bar(x_pos_, y, yerr=ye,  align='center', alpha=0.5, ecolor='black', capsize=10, error_kw=dict(lw=0.8, capsize=1, capthick=0.8,lolims=True),color=(gray,gray,gray,1))\n",
    "\n",
    "    L = [\"Automation/manual\",\"Manual/manual\"]\n",
    "    ax.legend(L)\n",
    "\n",
    "    ax.set_xticks(np.arange(len(M_l_sort)))\n",
    "    ln = [lm_names_merged_lr[int(lm)] for lm in M_l_sort]\n",
    "    ax.set_xticklabels(ln, rotation=90)\n",
    "\n",
    "    ax.set_yticks(np.arange(10)/10.0)\n",
    "    ax.set_yticklabels([str(a*1) for a in np.arange(10)], rotation=0)\n",
    "\n",
    "    ax.set_ylabel(\"displacement in 100Î¼m\")\n",
    "    ax.set_xlabel(\"Average landmark displacement\")\n",
    "    \n",
    "    ax.tick_params(axis='x', which='major', labelsize=6)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=8)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.title(\"Manual/manual vs automation/manual\")\n",
    "    plt.ylim([0,0.9])\n",
    "    plt.xlim([-0.5,len(x_pos)-0.5])\n",
    "    \n",
    "    \n",
    "    plt.savefig('BMCR_Figures/Fig18/landmarks_displacement_sorted.pdf', bbox_inches = 'tight',  pad_inches = 0.1)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d83b8ff-0455-4411-9d97-41cc0dbfe61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(all_dists.keys())\n",
    "\n",
    "init = True\n",
    "for a in range(3):\n",
    "    \n",
    "    print(\"best ANTs candidate \",keys[a])\n",
    "    if init:\n",
    "        init=False\n",
    "        ants = all_dists[keys[a]][...,None]\n",
    "        human = all_dists[keys[a+3]][...,None]\n",
    "    else:\n",
    "        ants = np.concatenate((ants,all_dists[keys[a]][...,None]),axis=2)\n",
    "        human = np.concatenate((human,all_dists[keys[a+3]][...,None]),axis=2)\n",
    "            \n",
    "\n",
    "ants = np.sort(ants,axis=2)[:,:,1]\n",
    "human = np.sort(human,axis=2)[:,:,1]\n",
    "            \n",
    "ants_worse_than_human = (ants>human).sum(axis=1)            \n",
    "human_worse_than_ants = (ants<human).sum(axis=1)            \n",
    "\n",
    "x_pos = np.arange(ants_worse_than_human.shape[0])\n",
    "fig, ax = plt.subplots()\n",
    "for a in range(2):\n",
    "    norm = ants_worse_than_human + human_worse_than_ants\n",
    "    offset = 0.1\n",
    "    if a == 0:   \n",
    "        hatch = \"/\"\n",
    "        hatch = \".O\"\n",
    "        hatch = \"..\"\n",
    "        hatch = \"x.\"\n",
    "        hatch = \"*\"\n",
    "        hatch = \".\"\n",
    "        for b in range(len(x_pos)):\n",
    "            hatch = \"/\" if b%2==0 else \".\"\n",
    "            hatch = \"\"\n",
    "            color = (0.5,0.5,0.5,1) if b%2==0 else (0.6,0.6,0.6,1)\n",
    "            ax.bar(x_pos[b]*2+offset, ants_worse_than_human[b]/norm[b], align='center', alpha=1, ecolor='red', capsize=10,color=color, hatch=hatch)\n",
    "    else:\n",
    "        for b in range(len(x_pos)):\n",
    "            hatch = \"/\" if b%2==0 else \".\"\n",
    "            hatch = \"\"\n",
    "            color = (1.0,0.5,0.5,1) if b%2==0 else (1.0,0.6,0.6,1)\n",
    "            ax.bar(x_pos[b]*2+1-offset, human_worse_than_ants[b]/norm[b], align='center', alpha=1, ecolor='red', capsize=10,color=color, hatch=hatch)\n",
    "\n",
    "\n",
    "gray_patch = mpatches.Patch(color=(0.5,0.5,0.5,1), label=\"Manual better\")\n",
    "red_patch = mpatches.Patch(color=(1.0,0.5,0.5,1), label=\"Automation better\")\n",
    "\n",
    "plt.legend(handles=[red_patch,gray_patch])\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "ax.set_xticks(np.arange(len(lm_names_merged_lr))*2+0.5)\n",
    "ax.set_xticklabels(lm_names_merged_lr, rotation=90)\n",
    "\n",
    "ax.set_yticks(np.arange(11)/10)\n",
    "ax.set_yticklabels([str(a*10)+\"%\" for a in np.arange(11)])\n",
    "\n",
    "ax.set_ylabel(\"\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.title(\"Better agreement : Automation/manual vs Manual/manual \")\n",
    "plt.xlim([-0.5,2*len(ants_worse_than_human)-0.5])\n",
    "plt.ylim([0,1])\n",
    "\n",
    "plt.savefig('BMCR_Figures/Fig18//landmarks_displacement_scores.pdf', bbox_inches = 'tight',  pad_inches = 0.1)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a486870-e475-499a-a6ea-fa751fc6bf55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
